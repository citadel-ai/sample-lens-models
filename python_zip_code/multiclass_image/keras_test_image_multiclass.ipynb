{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1a0a5185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not installed, install\n",
    "# !pip install tensorflow\n",
    "# !pip install Keras==3.6.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500f8e23",
   "metadata": {},
   "source": [
    "### Data Store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe7241a",
   "metadata": {},
   "source": [
    "#### 1. prepare data/imagewoof2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7912ed0",
   "metadata": {},
   "source": [
    "#### 2. extract each of the ZIP files under the 'imagewoof2' directory and prepare the respective directories.\n",
    "\n",
    "train https://drive.google.com/file/d/1rpTlk8osa-6zRk_akwvwlBGgICdnqqp-/view?usp=share_link \n",
    "\n",
    "val https://drive.google.com/file/d/1w33bjMpCuKgFw7XtlIl-uM3m9dQ3uRak/view?usp=share_link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3995c2",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2baac7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-15 23:07:04.385644: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-15 23:07:04.576327: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1734304024.598739   30480 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1734304024.605552   30480 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-15 23:07:04.629258: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "from zipfile import ZipFile\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.applications import mobilenet_v2\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from tensorflow.keras.layers import Dense, Flatten, Lambda\n",
    "\n",
    "from torch import argmax, jit, nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6e8fee",
   "metadata": {},
   "source": [
    "## Train the Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d7a134",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image_size = (256, 256)\n",
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "932960c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'data/imagewoof2/train'\n",
    "valid_dir = 'data/imagewoof2/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f1663c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9025 files belonging to 10 classes.\n",
      "Found 9025 files belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load the tensorflow Dataset\n",
    "train_ds = image_dataset_from_directory(train_dir, \n",
    "                                        seed=123, \n",
    "                                        shuffle=True,\n",
    "                                        batch_size=32,\n",
    "                                        image_size=input_image_size)\n",
    "val_ds = image_dataset_from_directory(valid_dir,\n",
    "                                      shuffle=True,\n",
    "                                      batch_size=32,\n",
    "                                      image_size=input_image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a70a7ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.RandomFlip(\"horizontal\"),\n",
    "        keras.layers.RandomRotation(0.1),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "877af901",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import (\n",
    "    MobileNetV2,\n",
    "    ResNet50,\n",
    "    Xception,\n",
    "    EfficientNetB0,\n",
    "    mobilenet_v2,\n",
    "    resnet,\n",
    "    xception,\n",
    "    efficientnet,\n",
    ")\n",
    "\n",
    "model_names = [MobileNetV2, ResNet50, Xception, EfficientNetB0]\n",
    "preproc_names = [\n",
    "    mobilenet_v2.preprocess_input,\n",
    "    resnet.preprocess_input,\n",
    "    xception.preprocess_input,\n",
    "    efficientnet.preprocess_input,\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e114532a",
   "metadata": {},
   "source": [
    "# Fine tune model with last layer re-tuned on this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f8e0214f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30480/3874289574.py:7: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = model_arch(weights=\"imagenet\",\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 843ms/step - accuracy: 0.8788 - loss: 1.5217 - val_accuracy: 0.9717 - val_loss: 0.4251\n",
      "Epoch 2/2\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 838ms/step - accuracy: 0.9753 - loss: 0.4247 - val_accuracy: 0.9849 - val_loss: 0.2666\n",
      "Saving model to MobileNetV2_keras_saved_model.keras\n",
      "ResNet50\n",
      "Epoch 1/2\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m924s\u001b[0m 3s/step - accuracy: 0.7814 - loss: 7.0019 - val_accuracy: 0.9427 - val_loss: 1.8132\n",
      "Epoch 2/2\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m919s\u001b[0m 3s/step - accuracy: 0.9641 - loss: 0.9824 - val_accuracy: 0.9825 - val_loss: 0.3952\n",
      "Saving model to ResNet50_keras_saved_model.keras\n",
      "Xception\n",
      "Epoch 1/2\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1115s\u001b[0m 4s/step - accuracy: 0.8934 - loss: 1.6019 - val_accuracy: 0.9631 - val_loss: 0.7773\n",
      "Epoch 2/2\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1105s\u001b[0m 4s/step - accuracy: 0.9614 - loss: 0.8114 - val_accuracy: 0.9803 - val_loss: 0.2588\n",
      "Saving model to Xception_keras_saved_model.keras\n",
      "EfficientNetB0\n",
      "Epoch 1/2\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m355s\u001b[0m 1s/step - accuracy: 0.8532 - loss: 1.3777 - val_accuracy: 0.9693 - val_loss: 0.3738\n",
      "Epoch 2/2\n",
      "\u001b[1m283/283\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m346s\u001b[0m 1s/step - accuracy: 0.9647 - loss: 0.5287 - val_accuracy: 0.9875 - val_loss: 0.1570\n",
      "Saving model to EfficientNetB0_keras_saved_model.keras\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "for model_arch, pre_proc in zip(model_names, preproc_names):\n",
    "    print(str(model_arch.__name__))\n",
    "    \n",
    "    base_model = model_arch(weights=\"imagenet\", \n",
    "                            input_shape=(input_image_size[0], input_image_size[1], 3), \n",
    "                            include_top=False, classes=n_classes)\n",
    "    \n",
    "    base_model.trainable = False\n",
    "    \n",
    "    inputs = keras.Input(shape=(None, None, 3))\n",
    "    resized =keras.layers.Resizing(input_image_size[0], input_image_size[1])(inputs)\n",
    "    processed = pre_proc(resized)\n",
    "\n",
    "    base = base_model(processed)\n",
    "    outputs = Dense(n_classes, activation='softmax')(Flatten()(base))\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    model.compile('adam', 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(train_ds, epochs=2, validation_data=val_ds)\n",
    "\n",
    "    # 保存形式を変更\n",
    "    model_name = f'{model_arch.__name__}_keras_saved_model.keras'\n",
    "    print(f'Saving model to {model_name}')\n",
    "    model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d2c55cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare requirements.txt\n",
    "!pip freeze | grep -E \"tensorflow|keras|numpy\" > requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c322597",
   "metadata": {},
   "source": [
    "### ZIP ACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "516cea16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "# select EfficientNetB0_keras_saved_model.keras\n",
    "with zipfile.ZipFile('multiclass_model_package_image.zip', 'w') as zf:\n",
    "    zf.write('EfficientNetB0_keras_saved_model.keras')\n",
    "    zf.write('requirements.txt')\n",
    "    zf.write('pred.py')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
